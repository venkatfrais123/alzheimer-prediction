{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbCjZ2HSKYNk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gdown\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from os.path import join\n",
        "import PIL \n",
        "import random\n",
        "import cv2 as cv\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rqzuk__oL9U2"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3317vSS0KTi"
      },
      "outputs": [],
      "source": [
        "DEFAULT_PATH = \"/content/drive/MyDrive/MS-Upgrad/MildDemented/\"\n",
        "# DEFAULT_PATH = \"/content/drive/MyDrive/MS-Upgrad/ModerateDemented/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LezMD48GKdfp"
      },
      "outputs": [],
      "source": [
        "dataset = keras.preprocessing.image_dataset_from_directory(\n",
        "    DEFAULT_PATH, label_mode=None, image_size=(128, 128), batch_size=32\n",
        ")\n",
        "dataset = dataset.map(lambda x: x / 255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3QRIQ0-KvVi"
      },
      "outputs": [],
      "source": [
        "for x in dataset:\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAAbi4PFKzqx"
      },
      "outputs": [],
      "source": [
        "# discriminator model\n",
        "\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(128,128,3)),\n",
        "        layers.Conv2D(128, kernel_size=3, strides=2, padding='same'),\n",
        "        layers.ZeroPadding2D(padding=((0,1),(0,1))),\n",
        "        layers.BatchNormalization(momentum=0.8),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Conv2D(128, kernel_size=3, strides=2, padding='same'),\n",
        "        layers.BatchNormalization(momentum=0.8),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Conv2D(256, kernel_size=3, strides=2, padding='same'),\n",
        "        layers.BatchNormalization(momentum=0.8),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Conv2D(512, kernel_size=3, strides=2, padding='same'),\n",
        "        layers.BatchNormalization(momentum=0.8),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1, activation=\"sigmoid\")\n",
        "    ],\n",
        "    name='discriminator'\n",
        ")\n",
        "\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7NhkQoCK2uD"
      },
      "outputs": [],
      "source": [
        "# generator model\n",
        "\n",
        "latent_dim = 128\n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(4 * 4 * 512, activation='relu'),\n",
        "        layers.Reshape((4, 4, 512)),\n",
        "        layers.UpSampling2D(),\n",
        "        layers.Conv2D(512, kernel_size=3, padding='same'),\n",
        "        layers.BatchNormalization(momentum=0.8),\n",
        "        layers.Activation('relu'),\n",
        "        layers.UpSampling2D(),\n",
        "        layers.Conv2D(512, kernel_size=3, padding='same'),\n",
        "        layers.BatchNormalization(momentum=0.8),\n",
        "        layers.Activation('relu'),\n",
        "        layers.UpSampling2D(),\n",
        "        layers.Conv2D(256, kernel_size=3, padding='same'),\n",
        "        layers.BatchNormalization(momentum=0.8),\n",
        "        layers.Activation('relu'),\n",
        "        layers.UpSampling2D(),\n",
        "        layers.Conv2D(256, kernel_size=3, padding='same'),\n",
        "        layers.BatchNormalization(momentum=0.8),\n",
        "        layers.Activation('relu'),\n",
        "        layers.UpSampling2D(),\n",
        "        layers.Conv2D(128, kernel_size=3, padding='same'),\n",
        "        layers.BatchNormalization(momentum=0.8),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Conv2D(3, kernel_size=3, padding='same'),\n",
        "        layers.Activation('tanh')\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjKKzl7dK7Iu"
      },
      "outputs": [],
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # fake images decoding\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combined images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # discriminations\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb_JUnbzK_bc"
      },
      "outputs": [],
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        for i in range(self.num_img):\n",
        "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save(\"generated_img_%03d_%d.jpg\" % (epoch, i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91vtIkOFLCH2"
      },
      "outputs": [],
      "source": [
        "epochs = 2000\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=2, latent_dim=latent_dim)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVPOjTUhLE9V"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MAxUvqUYxXm"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(discriminator,to_file='discriminator.png', show_shapes=True, dpi=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiCNq1CvY4Vh"
      },
      "outputs": [],
      "source": [
        "data_folder = \"/content/drive/MyDrive/MS-Upgrad\"\n",
        "\n",
        "## images GAN MildDemented\n",
        "df_MildDemented_GAN = pd.DataFrame({\n",
        "    \"X\": sorted(glob(join(data_folder, \"MildDementedGAN\", \"*\"))),\n",
        "    \"y\": 0,\n",
        "    \"class\": \"MildDemented\"\n",
        "})\n",
        "shuffled_mild_gan = df_MildDemented_GAN.sample(frac=1)\n",
        "testsize_mild_gan = int(0.2 * len(shuffled_mild_gan))\n",
        "# Test\n",
        "mild_test_gan = shuffled_mild_gan[:testsize_mild_gan]\n",
        "# Train and validation\n",
        "mild_trainval_gan = shuffled_mild_gan[testsize_mild_gan:]\n",
        "trainsize_mild_gan = int(0.8 * len(mild_trainval_gan))\n",
        "# Train\n",
        "shuffled_mild_gan_train = mild_trainval_gan[:trainsize_mild_gan]\n",
        "#Validation\n",
        "shuffled_mild_gan_val = mild_trainval_gan[trainsize_mild_gan:]\n",
        "\n",
        "\n",
        "## images GAN ModerateDemented\n",
        "df_ModerateDemented_gan = pd.DataFrame({\n",
        "    \"X\": sorted(glob(join(data_folder, \"ModerateDementedGAN\", \"*\"))),\n",
        "    \"y\": 0,\n",
        "    \"class\": \"ModerateDemented\"\n",
        "})\n",
        "shuffled_moderate_gan = df_ModerateDemented_gan.sample(frac=1)\n",
        "testsize_moderate_gan = int(0.2 * len(shuffled_moderate_gan))\n",
        "# Test\n",
        "moderate_test_gan = shuffled_moderate_gan[:testsize_moderate_gan]\n",
        "# Train and validation\n",
        "moderate_trainval_gan = shuffled_moderate_gan[testsize_moderate_gan:]\n",
        "trainsize_moderate_gan = int(0.8 * len(moderate_trainval_gan))\n",
        "# Train\n",
        "shuffled_moderate_gan_train = moderate_trainval_gan[:trainsize_moderate_gan]\n",
        "#Validation\n",
        "shuffled_moderate_gan_val = moderate_trainval_gan[trainsize_moderate_gan:]\n",
        "\n",
        "\n",
        "## images NonDemented\n",
        "df_NonDemented_imgs = pd.DataFrame({\n",
        "    \"X\": sorted(glob(join(data_folder, \"Alzheimer_MRI_4_classes_dataset/NonDemented\", \"*\"))),\n",
        "    \"y\": 0,\n",
        "    \"class\": \"NonDementia\"\n",
        "})\n",
        "shuffled_non = df_NonDemented_imgs.sample(frac=1)\n",
        "testsize_non = int(0.2 * len(shuffled_non))\n",
        "# Test\n",
        "non_test = shuffled_non[:testsize_non]\n",
        "# Train and validation\n",
        "non_trainval = shuffled_non[testsize_non:]\n",
        "trainsize_non = int(0.8 * len(non_trainval))\n",
        "# Train\n",
        "shuffled_non_train = non_trainval[:trainsize_non]\n",
        "#Validation\n",
        "shuffled_non_val = non_trainval[trainsize_non:]\n",
        "\n",
        "\n",
        "## images VeryMildDemented\n",
        "df_VeryMildDemented_imgs = pd.DataFrame({\n",
        "    \"X\": sorted(glob(join(data_folder, \"Alzheimer_MRI_4_classes_dataset/VeryMildDemented\", \"*\"))),\n",
        "    \"y\": 1,\n",
        "    \"class\": \"VeryMildDementia\"\n",
        "})\n",
        "shuffled_verymild = df_VeryMildDemented_imgs.sample(frac=1)\n",
        "testsize_verymild = int(0.2 * len(shuffled_verymild))\n",
        "\n",
        "# Test\n",
        "verymild_test = shuffled_verymild[:testsize_verymild]\n",
        "\n",
        "# Train and validation\n",
        "verymild_trainval = shuffled_verymild[testsize_verymild:]\n",
        "trainsize_verymild = int(0.8 * len(verymild_trainval))\n",
        "\n",
        "# Train\n",
        "shuffled_verymild_train = verymild_trainval[:trainsize_verymild]\n",
        "\n",
        "#Validation\n",
        "shuffled_verymild_val = verymild_trainval[trainsize_verymild:]\n",
        "\n",
        "\n",
        "## images MildDemented\n",
        "df_MildDemented_imgs = pd.DataFrame({\n",
        "    \"X\": sorted(glob(join(data_folder, \"Alzheimer_MRI_4_classes_dataset/MildDemented\", \"*\"))),\n",
        "    \"y\": 2,\n",
        "    \"class\": \"MildDementia\"\n",
        "})\n",
        "shuffled_mild = df_MildDemented_imgs.sample(frac=1)\n",
        "testsize_mild = int(0.2 * len(shuffled_mild))\n",
        "\n",
        "# Test\n",
        "mild_test = shuffled_mild[:testsize_mild]\n",
        "\n",
        "# Train and validation\n",
        "mild_trainval = shuffled_mild[testsize_mild:]\n",
        "trainsize_mild = int(0.8 * len(mild_trainval))\n",
        "\n",
        "# Train\n",
        "shuffled_mild_train = mild_trainval[:trainsize_mild]\n",
        "\n",
        "#Validation\n",
        "shuffled_mild_val = mild_trainval[trainsize_mild:]\n",
        "\n",
        "## images ModerateDemented\n",
        "df_ModerateDemented_imgs = pd.DataFrame({\n",
        "    \"X\": sorted(glob(join(data_folder, \"Alzheimer_MRI_4_classes_dataset/ModerateDemented\", \"*\"))),\n",
        "    \"y\": 3,\n",
        "    \"class\": \"ModerateDementia\"\n",
        "})\n",
        "shuffled_moderate = df_ModerateDemented_imgs.sample(frac=1)\n",
        "testsize_moderate = int(0.2 * len(shuffled_moderate))\n",
        "\n",
        "# Test\n",
        "moderate_test = shuffled_moderate[:testsize_moderate]\n",
        "\n",
        "# Train and validation\n",
        "moderate_trainval = shuffled_moderate[testsize_moderate:]\n",
        "trainsize_moderate = int(0.8 * len(moderate_trainval))\n",
        "\n",
        "# Train\n",
        "shuffled_moderate_train = moderate_trainval[:trainsize_moderate]\n",
        "\n",
        "#Validation\n",
        "shuffled_moderate_val = moderate_trainval[trainsize_moderate:]\n",
        "\n",
        "\n",
        "## Number of images\n",
        "print(\"TOTAL:\")\n",
        "print(\"# of images with NonDemented Alzheimer =\", len(shuffled_non))\n",
        "print(\"# of images with VeryMildDemented Alzheimer =\", len(shuffled_verymild))\n",
        "print(\"# of images with MildDemented Alzheimer =\", len(shuffled_mild))\n",
        "print(\"# of images with ModerateDemented Alzheimer =\", len(shuffled_moderate))\n",
        "print(\"# of images with MildDemented Alzheimer GAN =\", len(shuffled_mild_gan))\n",
        "print(\"# of images with ModerateDemented Alzheimer GAN =\", len(shuffled_moderate_gan))\n",
        "\n",
        "print(\"------------\")\n",
        "print(\"\\nTest:\")\n",
        "print(\"# of images with NonDemented Alzheimer =\", len(non_test))\n",
        "print(\"# of images with VeryMildDemented Alzheimer =\", len(verymild_test))\n",
        "print(\"# of images with MildDemented Alzheimer =\", len(mild_test))\n",
        "print(\"# of images with ModerateDemented Alzheimer =\", len(moderate_test))\n",
        "print(\"# of images with MildDemented Alzheimer GAN =\", len(mild_test_gan))\n",
        "print(\"# of images with ModerateDemented Alzheimer GAN =\", len(moderate_test_gan))\n",
        "print(\"------------\")\n",
        "print(\"\\nTraining:\")\n",
        "print(\"# of images with NonDemented Alzheimer =\", len(shuffled_non_train))\n",
        "print(\"# of images with VeryMildDemented Alzheimer =\", len(shuffled_verymild_train))\n",
        "print(\"# of images with MildDemented Alzheimer =\", len(shuffled_mild_train))\n",
        "print(\"# of images with ModerateDemented Alzheimer =\", len(shuffled_moderate_train))\n",
        "print(\"# of images with MildDemented Alzheimer GAN=\", len(shuffled_mild_gan_train))\n",
        "print(\"# of images with ModerateDemented Alzheimer GAN =\", len(shuffled_moderate_gan_train))\n",
        "print(\"------------\")\n",
        "print(\"\\nValidation:\")\n",
        "print(\"# of images with NonDemented Alzheimer =\", len(shuffled_non_val))\n",
        "print(\"# of images with VeryMildDemented Alzheimer =\", len(shuffled_verymild_val))\n",
        "print(\"# of images with MildDemented Alzheimer =\", len(shuffled_mild_val))\n",
        "print(\"# of images with ModerateDemented Alzheimer =\", len(shuffled_moderate_val))\n",
        "print(\"# of images with MildDemented Alzheimer gan=\", len(shuffled_mild_gan_val))\n",
        "print(\"# of images with ModerateDemented Alzheimer gan=\", len(shuffled_moderate_gan_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40tsClv183bp"
      },
      "outputs": [],
      "source": [
        "heights = [len(shuffled_non), len(shuffled_verymild), (len(shuffled_mild) + len(shuffled_mild_gan)), (len(shuffled_moderate) + len(shuffled_moderate_gan))]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "height = heights\n",
        "bars = ('Non', 'Very Mild', 'Mild', 'Moderate')\n",
        "y_pos = np.arange(len(bars))\n",
        "plt.bar(y_pos, height)\n",
        "plt.xticks(y_pos, bars)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0zY-N03-iLD"
      },
      "outputs": [],
      "source": [
        "def load_image(fname):\n",
        "    \"\"\"\n",
        "    Load an image using opencv given its path.\n",
        "    \"\"\"\n",
        "    # img is a numpy array\n",
        "    img = cv.imread(fname)\n",
        "    # opencv uses BGR channel order by default\n",
        "    # so convert to RGB\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "    # resize image\n",
        "    resize = (224, 224)\n",
        "    img = cv.resize(img, resize)\n",
        "    return img\n",
        "\n",
        "def hot_array(class_number):\n",
        "    ha = [0,0,0,0]\n",
        "    ha[class_number] = 1\n",
        "    return ha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxZUigidC99q"
      },
      "outputs": [],
      "source": [
        "# plot some images per class\n",
        "\n",
        "ncols = 10\n",
        "\n",
        "fig, axs = plt.subplots(nrows=4, ncols=ncols, figsize=(20, 10))\n",
        "\n",
        "for fname,ax in zip(shuffled_mild_gan.loc[:ncols, \"X\"], axs[0,:]):\n",
        "    im = load_image(fname)\n",
        "    ax.imshow(im)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.grid(False)\n",
        "\n",
        "for fname,ax in zip(shuffled_mild.loc[:ncols, \"X\"], axs[2,:]):\n",
        "    im = load_image(fname)\n",
        "    ax.imshow(im)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.grid(False)\n",
        "\n",
        "for fname,ax in zip(shuffled_moderate_gan.loc[:ncols, \"X\"], axs[1,:]):\n",
        "    im = load_image(fname)\n",
        "    ax.imshow(im)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.grid(False)\n",
        "\n",
        "\n",
        "for fname,ax in zip(shuffled_moderate.loc[:ncols, \"X\"], axs[3,:]):\n",
        "    im = load_image(fname)\n",
        "    ax.imshow(im)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.grid(False)\n",
        "\n",
        "axs[0,0].set_ylabel(\"Mild Dementia - GAN\")\n",
        "axs[1,0].set_ylabel(\"Mild Dementia\")\n",
        "axs[2,0].set_ylabel(\"Moderate Dementia - GAN\")\n",
        "axs[3,0].set_ylabel(\"Moderate Dementia\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX_RRbj9DMZa"
      },
      "outputs": [],
      "source": [
        "from psutil import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpCcBKuoR6fo"
      },
      "outputs": [],
      "source": [
        "cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNs59a2JR9O_"
      },
      "outputs": [],
      "source": [
        "cpu_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4-y_CM5R_Xf"
      },
      "outputs": [],
      "source": [
        "!cat /proc/cpuinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ffO_7b1SBru"
      },
      "outputs": [],
      "source": [
        "!df -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bskqzNVSFSb"
      },
      "outputs": [],
      "source": [
        "virtual_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2WpK3X0SGlh"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaTiF2EeS_dc"
      },
      "outputs": [],
      "source": [
        "!lscpu | grep \"L3 cache\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBhRYCB2TOzg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "alzheimer-gan.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}